{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from typing import Union, Dict, Any\n",
    "\n",
    "\n",
    "class Config:\n",
    "    # Embedded configuration data\n",
    "    _config_data: Dict[str, Any] = {\n",
    "        \"log_level\": \"DEBUG\",\n",
    "        \"tucson_center_coordinates\": [32.2226, -110.9747],\n",
    "        \"tucson_bounds\": [-111, 32.0, -110.9747, 32.2226],\n",
    "        \"paths\": {\"visualizations\": \"visualizations\"},\n",
    "        \"data_sources\": {\n",
    "            \"arrests\": \"https://raw.githubusercontent.com/christian-byrne/tucson-crime-models/main/data/crime/Tucson_Police_Arrests_-_2017_-_Open_Data.geojson\",\n",
    "            \"sidewalks\": \"https://raw.githubusercontent.com/christian-byrne/tucson-crime-models/main/data/infrastructure/Sidewalks.geojson\",\n",
    "        },\n",
    "    }\n",
    "\n",
    "    # Root path for resolving paths\n",
    "    ROOT_PATH: Path = Path(\".\").resolve()\n",
    "\n",
    "    @staticmethod\n",
    "    def get_proj_root(cls) -> Path:\n",
    "        \"\"\"Return the root path of the project.\"\"\"\n",
    "        return Config.ROOT_PATH\n",
    "\n",
    "    def __getitem__(self, key: str) -> Any:\n",
    "        \"\"\"Get a configuration value by key, with KeyError if missing.\"\"\"\n",
    "        if key not in Config._config_data:\n",
    "            msg = (\n",
    "                f\"Could not find key '{key}' in config.\"\n",
    "                + f\"Available keys: {list(Config._config_data.keys())}\"\n",
    "            )\n",
    "            raise KeyError(msg)\n",
    "        return Config._config_data[key]\n",
    "\n",
    "    def __setitem__(self, key: str, value: Union[str, Path]) -> None:\n",
    "        \"\"\"Set a configuration value by key, converting Path to string if necessary.\"\"\"\n",
    "        if isinstance(value, Path):\n",
    "            value = str(value.resolve())\n",
    "        Config._config_data[key] = value\n",
    "\n",
    "    @classmethod\n",
    "    def get_all(cls) -> Dict[str, Any]:\n",
    "        \"\"\"Return the entire configuration data dictionary.\"\"\"\n",
    "        return cls._config_data\n",
    "    \n",
    "config = Config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from rich.logging import RichHandler\n",
    "\n",
    "\n",
    "class Logger:\n",
    "    def __init__(self, logger_name: str, level: int = logging.INFO):\n",
    "        self.logger_base = logging.getLogger(logger_name)\n",
    "\n",
    "        # Only add the RichHandler if there are no existing handlers\n",
    "        if not self.logger_base.handlers:\n",
    "            rich_handler = RichHandler(\n",
    "                rich_tracebacks=True, tracebacks_show_locals=True, markup=True\n",
    "            )\n",
    "\n",
    "            formatter = logging.Formatter(\"%(message)s\")\n",
    "            rich_handler.setFormatter(formatter)\n",
    "\n",
    "            self.logger_base.addHandler(rich_handler)\n",
    "\n",
    "        # Set the logging level\n",
    "        self.logger_base.setLevel(level)\n",
    "\n",
    "    def __call__(self):\n",
    "        return self.logger_base\n",
    "\n",
    "\n",
    "logger = Logger(\"General\", config[\"log_level\"])()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import requests\n",
    "from typing import Dict\n",
    "\n",
    "# Dictionary to cache datasets in memory to prevent re-fetching in same session\n",
    "_cache: Dict[str, gpd.GeoDataFrame] = {}\n",
    "\n",
    "\n",
    "def load_dataset(dataset_name: str):\n",
    "    # Check if the dataset is already cached\n",
    "    if dataset_name in _cache:\n",
    "        logger.info(f\"Using cached data for {dataset_name}\")\n",
    "        return _cache[dataset_name]\n",
    "\n",
    "    # Load the dataset from Config if not cached\n",
    "    filepath = config[\"data_sources\"][dataset_name]\n",
    "\n",
    "    if filepath.startswith(\"http\"):\n",
    "        logger.info(f\"Downloading dataset from {filepath}\")\n",
    "        response = requests.get(filepath)\n",
    "        response.raise_for_status()\n",
    "        with open(f\"/tmp/{dataset_name}.geojson\", \"wb\") as f:\n",
    "            f.write(response.content)\n",
    "        dataframe = gpd.read_file(f\"/tmp/{dataset_name}.geojson\")\n",
    "    else:\n",
    "        dataframe = gpd.read_file(filepath)\n",
    "\n",
    "    logger.info(f\"Loaded data from {filepath}\")\n",
    "    logger.debug(\n",
    "        f\"Columns in {filepath.split('/')[-1]}:\\n{', '.join(dataframe.columns)}\"\n",
    "    )\n",
    "\n",
    "    # Cache the loaded dataset\n",
    "    _cache[dataset_name] = dataframe\n",
    "\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Filter Geographic Information System (GIS) Data by Bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import box\n",
    "\n",
    "\n",
    "def filter_by_bounds(data: gpd.GeoDataFrame, bounds: tuple) -> gpd.GeoDataFrame:\n",
    "    \"\"\"\n",
    "    Filters the GeoDataFrame to include only points within the specified bounds.\n",
    "\n",
    "    Parameters:\n",
    "    data (GeoDataFrame): The data to filter.\n",
    "    bounds (tuple): A tuple (minx, miny, maxx, maxy) defining the bounding box.\n",
    "\n",
    "    Returns:\n",
    "    GeoDataFrame: Filtered GeoDataFrame with points within the bounds.\n",
    "    \"\"\"\n",
    "    logger.debug(f\"Filtering data by bounds: {bounds}\")\n",
    "    bbox = box(*bounds)\n",
    "\n",
    "    if len(data) == 0:\n",
    "        logger.error(\"No data found in the input GeoDataFrame. Check the input data.\")\n",
    "        return data\n",
    "\n",
    "    # Filter data by checking if geometry is within the bounding box\n",
    "    before_length = len(data)\n",
    "    filtered = data[data.geometry.within(bbox)]\n",
    "    logger.info(f\"Filtered out {before_length - len(filtered)} rows outside the bounds\")\n",
    "\n",
    "    if len(data) == len(filtered):\n",
    "        logger.warning(\"All data is within the specified bounds. No data was filtered.\")\n",
    "\n",
    "    if len(filtered) == 0:\n",
    "        logger.error(\n",
    "            f\"All data was filtered out. Check that the bounds {bounds} are correct.\"\n",
    "        )\n",
    "\n",
    "    return filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Plot GIS Data on a Geographic Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "\n",
    "\n",
    "def create_map(\n",
    "    data: gpd.GeoDataFrame,\n",
    "    location: list = None,\n",
    "    zoom_start: int = 12,\n",
    "    popup_field: Optional[str] = None,\n",
    "    save_path: Union[str, Path, None] = None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Create a folium map with markers for each point in the input GeoDataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    data (GeoDataFrame): The data to plot, must contain 'geometry' column.\n",
    "    location (list): Latitude and longitude to center the map on. Default is Tucson, AZ.\n",
    "    zoom_start (int): Initial zoom level for the map.\n",
    "    popup_field (str, optional): Column name to use for the marker popups. If None, no popups.\n",
    "    save_path (str or Path, optional): Path to save the generated map HTML file.\n",
    "\n",
    "    Returns:\n",
    "    folium.Map: A map with a marker for each point in data.\n",
    "    \"\"\"\n",
    "    # Default location to Tucson, AZ if not provided\n",
    "    location = location or [32.2226, -110.9747]\n",
    "\n",
    "    logger.info(f\"Creating map centered at {location} with zoom level {zoom_start}...\")\n",
    "    crime_map = folium.Map(location=location, zoom_start=zoom_start)\n",
    "\n",
    "    logger.debug(\"Filtering out rows with missing or non-Point geometry\")\n",
    "    data = data[data.geometry.notnull() & (data.geometry.type == \"Point\")]\n",
    "\n",
    "    logger.info(f\"Adding {len(data)} points to the map\")\n",
    "    for _, row in data.iterrows():\n",
    "        # Retrieve the popup content if specified and available\n",
    "        popup_text = (\n",
    "            str(row[popup_field]) if popup_field and popup_field in row else None\n",
    "        )\n",
    "        folium.Marker([row.geometry.y, row.geometry.x], popup=popup_text).add_to(\n",
    "            crime_map\n",
    "        )\n",
    "\n",
    "    # Save map to HTML if save_path is specified\n",
    "    if save_path:\n",
    "        save_path = Path(save_path) if isinstance(save_path, str) else save_path\n",
    "        crime_map.save(save_path)\n",
    "        logger.info(f\"Map saved at {save_path}\")\n",
    "\n",
    "    # Display the map inline in the notebook\n",
    "    # display(crime_map)\n",
    "\n",
    "    return crime_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Joining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_data(\n",
    "    left: gpd.GeoDataFrame,\n",
    "    right: gpd.GeoDataFrame,\n",
    "    left_key: str,\n",
    "    right_key: str,\n",
    "    how: str = \"left\",\n",
    ") -> gpd.GeoDataFrame:\n",
    "    \"\"\"\n",
    "    Join two GeoDataFrames based on a common key.\n",
    "\n",
    "    Parameters:\n",
    "    left (GeoDataFrame): The left GeoDataFrame to join.\n",
    "    right (GeoDataFrame): The right GeoDataFrame to join.\n",
    "    left_key (str): The column name to join on in the left GeoDataFrame.\n",
    "    right_key (str): The column name to join on in the right GeoDataFrame.\n",
    "    how (str): The type of join to perform. Default is 'left'.\n",
    "\n",
    "    Returns:\n",
    "    GeoDataFrame: A GeoDataFrame with the joined data.\n",
    "    \"\"\"\n",
    "    logger.info(f\"Joining data on {left_key} with {right_key} using {how} join\")\n",
    "    joined = left.merge(right, how=how, left_on=left_key, right_on=right_key)\n",
    "\n",
    "    if len(joined) == 0:\n",
    "        logger.error(\n",
    "            f\"No data was joined. Check that the keys {left_key} and {right_key} are correct.\"\n",
    "        )\n",
    "\n",
    "    return joined"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Join GIS Data based on Distance Comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: This approach works well for moderately sized datasets but could become slow for very large ones. For large datasets, spatial indexing or more advanced spatial joins might be needed (e.g., using scipyâ€™s cKDTree for faster nearest-neighbor searches).\n",
    "def distance_join(\n",
    "    main_gdf, ref_gdf, ref_col_name=\"nearest_id\", distance_col_name=\"distance_to\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Adds a column to the main GeoDataFrame with the ID of the nearest feature\n",
    "    from the reference GeoDataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    main_gdf (GeoDataFrame): The main GeoDataFrame, typically with Point geometries (e.g., arrests data).\n",
    "    ref_gdf (GeoDataFrame): The reference GeoDataFrame to find the nearest feature from (e.g., sidewalks).\n",
    "    ref_col (str): The name of the new column in main_gdf to store the ID of the nearest feature.\n",
    "    distance_col (str, optional): If provided, stores the distance to the nearest feature in this column.\n",
    "\n",
    "    Returns:\n",
    "    GeoDataFrame: The main GeoDataFrame with an added column for the nearest feature's ID.\n",
    "    \"\"\"\n",
    "    # Ensure both GeoDataFrames are in the same CRS, convert to a metric CRS for distance calculation\n",
    "    metric_crs = \"EPSG:3857\"\n",
    "    main_gdf = main_gdf.to_crs(metric_crs)\n",
    "    ref_gdf = ref_gdf.to_crs(metric_crs)\n",
    "\n",
    "    # Prepare the new columns in main_gdf\n",
    "    main_gdf[ref_col_name] = None\n",
    "    if distance_col_name:\n",
    "        main_gdf[distance_col_name] = None\n",
    "\n",
    "    # For each geometry in main_gdf, find the closest geometry in ref_gdf\n",
    "    for idx, main_geom in main_gdf.iterrows():\n",
    "        # Find the nearest geometry in ref_gdf\n",
    "        nearest_geom = ref_gdf.geometry.distance(main_geom.geometry).idxmin()\n",
    "\n",
    "        # Add the ID of the nearest geometry (index) to the main_gdf\n",
    "        main_gdf.at[idx, ref_col_name] = ref_gdf.at[\n",
    "            nearest_geom, \"OBJECTID\"\n",
    "        ]  # or another ID column in ref_gdf\n",
    "\n",
    "        # Optionally, store the distance to the nearest feature\n",
    "        if distance_col_name:\n",
    "            distance = main_geom.geometry.distance(ref_gdf.at[nearest_geom, \"geometry\"])\n",
    "            main_gdf.at[idx, distance_col_name] = distance\n",
    "\n",
    "    # Reproject main_gdf back to the original CRS\n",
    "    main_gdf = main_gdf.to_crs(ref_gdf.crs)\n",
    "\n",
    "    return main_gdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load *Arrests* Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arrests_data = load_dataset(\"arrests\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "arrests_data = arrests_data[arrests_data.geometry.notnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Truncate/Shrink Data for Fast Testing (Temporary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restrict to just Tucson\n",
    "arrests_data = filter_by_bounds(arrests_data, config[\"tucson_bounds\"])\n",
    "\n",
    "# Truncate\n",
    "arrests_data = arrests_data.head(300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize Arrests Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_map(arrests_data, popup_field=\"ArrestChargeandDescription\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load *Sidewalks* Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sidewalks_data = load_dataset(\"sidewalks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add `distance_to_nearest_sidewalk` to Arrests Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "arrests_data = distance_join(\n",
    "    arrests_data,\n",
    "    sidewalks_data,\n",
    "    ref_col_name=\"nearest_sidewalk_id\",\n",
    "    distance_col_name=\"distance_to_nearest_sidewalk\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analyze Correlation between Arrests Frequency and `distance_to_nearest_sidewalk`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(arrests_data[\"distance_to_nearest_sidewalk\"], kde=True, bins=30)\n",
    "plt.xlabel(\"Distance to Nearest Sidewalk (meters)\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Distribution of Distance to Nearest Sidewalk for Crime Incidents\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
